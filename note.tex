\documentclass{article}

\usepackage[T1]{fontenc}
\usepackage{algpseudocode}
\usepackage{algorithm} 

\title{Implementation}

\begin{document}

\maketitle{}

\date{}

\section{Implementation}

The crux of the dependency parser is Eisner's parsing algorithm. A slightly modified version of the same was used which is given below:


\begin{algorithm}
\begin{algorithmic}
  \State Initialization:
     \For{s = 0 to n}

        Form Triangle of size 1
        \State C[s][s][$\rightarrow$][1] = C[s][s][$\leftarrow$][1] = 0.0
        Form TriStop of size 1
        \State C[s][s][$\rightarrow$][2] = C[s][s][$\leftarrow$][2] = 0.0
\EndFor


\For{ k = 1 to n + 1}
  \For{s = 0 to n}


    \State t=s+k
     \State if t > n then break
     \State First: create Trapezium
      \State C[s][t][$\leftarrow$][0] = $max_{s \le r< t}$ (C[s][r][$\rightarrow$][1] + C[r + 1][t][$\leftarrow$][1] + S(t, s)) 
      \State C[s][t][$\rightarrow$][0] = $max_{s \le r<t}$ (C[s][r][$\rightarrow$][1] + C[r + 1][t][$\leftarrow$][1] + S(s, t)) 
      \State Second: create Triangle
      \State C[s][t][$\leftarrow$][1] = $max_{s \le r<t}$ (C[s][r][$\leftarrow$][1] + C[r][t][$\leftarrow$][0])
      \State C[s][t][$\rightarrow$][1] = $max_{s<r \le t}$ (C[s][r][$\rightarrow$][0] + C[r][t][$\rightarrow$][1])
      \State Second: create Tristop
      \State C[s][t][$\leftarrow$][1] = $max_{s \le r<t}$ (C[s][r][$\leftarrow$][1] + C[r][t][$\leftarrow$][0])
      \State C[s][t][$\rightarrow$][1] = $max_{s<r \le t}$ (C[s][r][$\rightarrow$][0] + C[r][t][$\rightarrow$][1])


\EndFor
\EndFor

      \State Return C[0][n][$\rightarrow$][1] as the highest score for any parse \\

\end{algorithmic}
\end{algorithm}


An open source library called PyDecode is used to build a hypergraph, with all the triangles, trapezium and Tristop formed in the Eisner's parsing algorithm as its nodes. The edges of the hypergraph are assigned weights according to certain rules. An edge has head word, modifier word, direction, adjacency and state values stored in it. The direction indicates the direction in which the edge is being formed. The adjacency indicates if the modifier word is the first child of the head word, in which case it is ``adj``, or not, in which case it is ``non-adj``. The edge joining a Triangle with TriStop to form a Trapezium is responsible for dependency probability. The edge forming a TriStop from a Triangle is used to calculate the stop probability. If an edge does not have a modifier, the modifier word is ``---``.

 The insideOutside algorithm is run on the entire hypergraph. The inside probability of the root of the hypergraph gives the total probability of the sentence Z. The marginals of the hypergraph are computed using the PyDecode library. The marginals = marginals / Z gives the counts for the EM algorithm.

The em algorithm is run 20 times for all the sentences. The hypergraph is built for each sentence. The stop and dep probabilities are incremented according to the following algorithm:


\begin{algorithm}
\begin{algorithmic}

\For{edge in hypergraph.edges}
   \State headWord, modWord, direct, adj, state = edge.label.split()

       \If{state == "1" and modWord != '---'}
          \State depCounts[headWord, modWord, direct] += marginals[edge.label]
        \EndIf


        \If{state == "0"}
          \State stopCounts[headWord, direct, adj] += marginals[edge.label]
        \EndIf

\EndFor

\end{algorithmic}
\end{algorithm}

\section{EM}


\begin{itemize}
\item sentence; $w_1 \ldots w_n$
\item vocabulary; ${\cal W}$
\item modifier; $m \in \{1 \ldots n\}$
\item head; $h \in \{0 \ldots n\}$
\item direction; ${\cal D}= \{\textrm{L}, \textrm{R}\}$
\item edge; ${\cal E}= \{\textrm{E(h, m!=--, dir, ADJ, cont=1)}, \textrm{E(h, m=--, dir, ADJ, cont=1)}, \textrm{E(h, dir, ADJ, cont=0)}\}$

The first edge \textrm{E(h, m!=--, ADJ, cont=1)} is created when a Triangle whose head word is still taking children combines with a tringle whose headword has stopped taking children (TriStop) to form a trapezium.

The edge \textrm{E(h, m=--, ADJ, cont=1)} is created when a Trapezium combines with a tringle whose headword has stopped taking children (TriStop) to form a Triangle.

The edge \textrm{E(h, dir, ADJ, cont=0)} is created when a Triangle's headword stops taking children to form TriStop.


\item marginals $p(edge)$
\end{itemize}


The probabilities 

\begin{itemize}
\item $p(\mathrm{CONT} | w, dir, \mathrm{ADJ})$; $\mathrm{CONT} \in \{0, 1\}$,  $w \in {\cal W}$, $\mathrm{ADJ} \in \{0, 1\}$, $dir \in \{0,1\}$
\item $c(\mathrm{CONT}, w, \mathrm{ADJ})$
\item $p(u | v, dir, \mathrm{ADJ})$; $\mathrm{CONT} \in \{0, 1\}$,  $u, v \in {\cal W}$, $\mathrm{ADJ} \in \{0, 1\}$
\item $c(u, v, dir)$
\item $c(u, v, dir, \mathrm{ADJ})$

\end{itemize}



Estimation Step


Fill in the $c$ charts. 



 \[c(\mathrm{CONT} = 0, h, dir, \mathrm{ADJ}= 1) \gets 
  \sum p(\mathrm{E(h, dir, ADJ=1, CONT = 0)}) \]

 \[c(\mathrm{CONT} = 0, h, dir, \mathrm{ADJ}= 0) \gets 
  \sum p(\mathrm{E(h, dir, ADJ=0, CONT = 0)}) \]

\[c(h, m, dir, \mathrm{ADJ}) \gets   \sum p(\mathrm{E(h, m!=--, dir, ADJ, CONT = 1)}) \]

\[c(h, m, dir) \gets   \sum\limits_{ADJ=\{0,1\}} p(\mathrm{E(h, m!=--, dir, CONT = 1)}) \]


Maximization Step

  \[p(\mathrm{CONT} | h, dir, \mathrm{ADJ}) \gets 
  \frac{c(\mathrm{CONT}, h, dir, \mathrm{ADJ})}{
    \sum_{m \in {\cal W}} c(h, m, dir, ADJ) + c(\mathrm{CONT}, h, dir, \mathrm{ADJ})} 
  \]



  \[p(m | h, dir) \gets 
  \frac{c(h, m, dir)}{
    \sum_{m \in {\cal W}} c(h, m, dir)}
  \]



\end{document}
